<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research (* = equal contribution)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html">Bio</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="courses.html">Courses</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research (* = equal contribution)</h1>
</div>
<h2>Research Interests</h2>
<p>My current interests include</p>
<ul>
<li><p>Convex and Nonconvex Optimization. </p>
</li>
<li><p>Computational Optimal Transport.</p>
</li>
<li><p>Algorithmic Game Theory. </p>
</li>
<li><p>Text Mining. </p>
</li>
</ul>
<h2>Refereed Publications </h2>
<ul>
<li><p><a href="https://arxiv.org/abs/1805.12344">An ADMM-Based Interior-Point Method for Large-Scale Linear Programming</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Shiqian Ma, Yinyu Ye and Shuzhong Zhang</p>
</li>
<li><p>To appear in <i>Optimization Methods and Software</i>, 2020</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1811.02427">A Unified Adaptive Tensor Approximation Scheme to Accelerate Composite Convex Optimization</a></p>
<ul>
<li><p>(α-β order) Bo Jiang, <b>Tianyi Lin</b> and Shuzhong Zhang</p>
</li>
<li><p><i>SIAM Journal on Optimization</i>, 30 (4): 2897-2926, 2020</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007%2Fs10589-018-0034-y">Structured Nonconvex Optimization Models: Algorithms and Iteration Complexity Analysis</a></p>
<ul>
<li><p>(α-β order) Bo Jiang, <b>Tianyi Lin</b>, Shiqian Ma and Shuzhong Zhang</p>
</li>
<li><p><i>Computational Optimization and Applications</i>, 72 (1): 115-157, 2019 </p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S092523121830482X">On the Iteration Complexity Analysis of Stochastic Primal-Dual Hybrid Gradient approach with High Probability</a></p>
<ul>
<li><p>Linbo Qiao, <b>Tianyi Lin</b>, Qi Qin and Xicheng Lu</p>
</li>
<li><p><i>Neurocomputing</i>, 307: 78-90, 2018</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10915-017-0612-7">Global Convergence of Unmodified 3-Block ADMM for a Class of Convex Minimization Problems</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Shiqian Ma and Shuzhong Zhang</p>
</li>
<li><p><i>Journal of Scientific Computing</i>, 76 (1): 69-88, 2018</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S0925231217313905">Stochastic Primal-Dual Proximal ExtraGradient Descent for Compositely Regularized Optimization</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Linbo Qiao, Teng Zhang, Jiashi Feng and Bofeng Zhang</p>
</li>
<li><p><i>Neurocomputing</i>, 273: 516-525, 2018</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://ieeexplore.ieee.org/document/7942055">Distributed Linearized Alternating Direction Method of Multipliers for Composite Convex Consensus Optimization</a></p>
<ul>
<li><p>Necdet S. Aybat, Zi Wang, <b>Tianyi Lin</b> and Shiqian Ma</p>
</li>
<li><p><i>IEEE Transactions on Automatic Control</i>, 63 (1): 5-20, 2018</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10208-015-9282-8">An Extragradient-Based Alternating Direction Method for Convex Minimization</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Shiqian Ma and Shuzhong Zhang</p>
</li>
<li><p><i>Foundations of Computational Mathematics</i>, 17 (1): 35-59, 2017</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10115-016-1005-1">Exploiting Interactions of Review Text, Hidden User Communities and Item Groups, and Time for Collaborative Filtering</a></p>
<ul>
<li><p>Yinqing Xu, Qian Yu, Wai Lam and <b>Tianyi Lin</b></p>
</li>
<li><p><i>Knowledge and Information Systems</i>, 52 (1): 221-254, 2017</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10915-016-0182-0">Iteration Complexity Analysis
of Multi-Block ADMM for a Family of Convex Minimization without Strong Convexity</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Shiqian Ma and Shuzhong Zhang</p>
</li>
<li><p><i>Journal of Scientific Computing</i>, 69: 52-81, 2016</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s40305-015-0092-0">On the Sublinear Convergence Rate of Multi-Block ADMM</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Shiqian Ma and Shuzhong Zhang</p>
</li>
<li><p><i>Journal of the Operations Research Society of China</i>, 3(3): 251-274, 2015</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://epubs.siam.org/doi/abs/10.1137/140971178">On the Global Linear Convergence of the ADMM with Multi-Block Variables</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Shiqian Ma and Shuzhong Zhang</p>
</li>
<li><p><i>SIAM Journal on Optimization</i>, 25 (3): 1478-1497, 2015</p>
</li>
</ul>

</li>
</ul>
<h2>Refereed Proceedings</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.07458">Projection Robust Wasserstein Distance and Riemannian Optimization</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Chenyou Fan*, Nhat Ho, Macro Cuturi and Michael I. Jordan</p>
</li>
<li><p>(<b>Spotlight</b>) <i>Neural Information Processing Systems (NeurIPS&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.04783">Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast Algorithm</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Nhat Ho, Xi Chen, Macro Cuturi and Michael I. Jordan</p>
</li>
<li><p><i>Neural Information Processing Systems (NeurIPS&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2007.09525">New Proximal Newton-Type Methods for Convex Optimization</a></p>
<ul>
<li><p>(α-β order) Ilan Adler, Zhiyue T. Hu and <b>Tianyi Lin</b></p>
</li>
<li><p><i>IEEE Conference on Decision and Control (CDC&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.09806">Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Zhengyuan Zhou*, Panayotis Mertikopoulos and Michael I. Jordan</p>
</li>
<li><p><i>International Conference on Machine Learning (ICML&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1906.00331">On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Chi Jin and Michael I. Jordan</p>
</li>
<li><p><i>International Conference on Machine Learning (ICML&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.02417">Near-Optimal Algorithms for Minimax Optimization</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Chi Jin and Michael I. Jordan</p>
</li>
<li><p><i>Conference on Learning Theory (COLT&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1806.00458">Improved Sample Complexity for Stochastic Compositional Variance Reduced Gradient</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Chenyou Fan, Mengdi Wang and Michael I. Jordan</p>
</li>
<li><p><i>American Control Conference (ACC&rsquo;20)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1901.06482">On Efficient Optimal Transport: An Analysis of Greedy and Accelerated Mirror Descent Algorithms</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Nhat Ho* and Michael I. Jordan</p>
</li>
<li><p><i>International Conference on Machine Learning (ICML&rsquo;19)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/1810.09079">Sparsemax and Relaxed Wasserstein for Topic Sparsity</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Zhiyue T. Hu and Xin Guo</p>
</li>
<li><p><i>ACM International Conference on Web Search and Data Mining (WSDM&rsquo;19)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://dl.acm.org/citation.cfm?id=2983765">Understanding Sparse Topical Structure of Short Text via Stochastic Variational-Gibbs Inference</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Siyuan Zhang and Hong Cheng</p>
</li>
<li><p><i>ACM Conference on Information and Knowledge Management (CIKM&rsquo;16)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://dl.acm.org/citation.cfm?id=3305612">On Stochastic Primal-Dual Hybrid Gradient Approach for Compositely Regularized Minimization</a></p>
<ul>
<li><p>Linbo Qiao, <b>Tianyi Lin</b>, Yugang Jiang, Fan Yang, Wei Liu and Xicheng Lu</p>
</li>
<li><p><i>European Conference on Artificial Intelligence (ECAI&rsquo;16)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://dl.acm.org/citation.cfm?id=2662059">Collaborative Filtering Incorporating Review Text and Co-clusters of Hidden User Communities and Item Groups</a></p>
<ul>
<li><p>Yinqing Xu, Wai Lam and <b>Tianyi Lin</b></p>
</li>
<li><p><i>ACM Conference on Information and Knowledge Management (CIKM&rsquo;14)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://dl.acm.org/citation.cfm?id=2661829.2662062">Latent Aspect Mining via Exploring Sparsity and Intrinsic Information</a></p>
<ul>
<li><p>Yinqing Xu, <b>Tianyi Lin</b>, Wai Lam, Zirui Zhou, Hong Cheng and Anthony M-C. So,</p>
</li>
<li><p><i>ACM Conference on Information and Knowledge Management (CIKM&rsquo;14)</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://dl.acm.org/citation.cfm?id=2567980">The Dual-Sparse Topic Model: Mining Focused Topics and Focused Terms in Short Text</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Wentao Tian*, Qiaozhu Mei and Hong Cheng</p>
</li>
<li><p><i>International World Wide Web Conference (WWW&rsquo;14)</i></p>
</li>
</ul>

</li>
</ul>
<h2>Preprints</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.12301">On Projection Robust Optimal Transport: Sample Complexity and Model Misspecification</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Zeyu Zheng, Elynn Y. Chen, Marco Cuturi and Michael I. Jordan</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1912.07168">A Control-Theoretic Perspective on Optimal High-Order Optimization</a></p>
<ul>
<li><p><b>Tianyi Lin</b> and Michael I. Jordan</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1910.00152">On the Complexity of Approximating Multimarginal Optimal Transport</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Nhat Ho, Macro Cuturi and Michael I. Jordan</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1906.01437">On the Efficiency of the Sinkhorn and Greenkhorn Algorithms and Their Acceleration for Optimal Transport</a></p>
<ul>
<li><p><b>Tianyi Lin</b>, Nhat Ho and Michael I. Jordan</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1904.07462">On Structured Filtering-Clustering: Global Error Bound and Optimal First-Order Algorithms</a></p>
<ul>
<li><p>Nhat Ho, <b>Tianyi Lin</b>* and Michael I. Jordan</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1802.05426">Adaptively Accelerating Cubic Regularized Newton's Methods for Convex Optimization via Random Sampling</a></p>
<ul>
<li><p>(α-β order) Xi Chen, Bo Jiang, <b>Tianyi Lin</b> and Shuzhong Zhang</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1705.07164">Relaxed Wasserstein with Applications to GANs</a></p>
<ul>
<li><p>(α-β order) Xin Guo, Johnny Hong, <b>Tianyi Lin</b> and Nan Yang</p>
</li>
</ul>

</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
